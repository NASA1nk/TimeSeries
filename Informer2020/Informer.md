LSTF模型，具有三个显著的特点

- ProbSparse Self-Attention，在时间复杂度和内存使用率上达到了O(LlogL)，在序列的依赖对齐上具有相当的性能。
- self-attention 提取通过将级联层输入减半来突出控制注意，并有效地处理超长的输入序列。
- 产生式decoder虽然概念上简单，但在一个正向操作中预测长时间序列，而不是一步一步地进行，这大大提高了长序列预测的推理速度。

