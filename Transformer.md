# Self-Attention

## 矩阵计算

矩阵计算可以看出行向量和列向量的**内积**

**内积的几何意义**是一个向量在另一个向量上的投影

- 投影的值大，说明两个向量的相关度高
- 如果两个向量夹角是九十度，内积为0，即这两个向量线性无关，完全没有相关性

## Softmax

**归一化**

- 让结果的这些概率的和为1