# 时间序列数据分析

time series

时间序列数据：按时间顺序排列的、随时间变化且相互关联的数据序列

时间序列数据分析：从按时间排序的数据点中抽取有价值的总结和统计信息的行为

- 对过去数据的诊断，对未来数据的预测

**时间序列和回归分析的区别**

核心区别在于对**数据的假设**

- 回归分析假设每个数据点都是**独立**的
- 时间序列则是利用数据之间的**相关性**进行预测

## 影响因素

时间序列的变化主要受到长期趋势、季节变动、周期变动和不规则变动这四个因素的影响

- **长期趋势因素**（T）：反映了在一个较长时间内的发展方向，它可以在一个相当长的时间内表现为一种近似直线的**持续向上或持续向下或平稳的趋势**
- **季节变动因素**（S）：是受季节变动影响所形成的一种**长度和幅度固定的周期波动**
- **周期变动因素**（C）：也称循环变动因素，它是受各种因素影响形成的上下起伏不定的波动
- **不规则变动因素**（I）：也称随机变动因素，它是受各种偶然因素影响所形成的不规则变动

## 应用

- **单指标时序预测任务**：给定某一个指标的历史变化情况，预测其在未来一段时间内的变化
- **多指标时序预测任务**：给定某几个指标的历史变化情况，预测其在未来一段时间内的变化
  - 该任务与单指标时序预测任务的区别在于，几个指标之间不一定相互独立，而是存在某种影响。
- **时序异常检测任务**：从正常的时间序列中识别不正常的事件或行为的过程
  - 可以从历史数据中检测，也可以基于时序预测对尚未发生的异常做出预警
- **时序指标聚类**：将变化趋势类似的时序指标归至同一类别
  - 在实际运维工作中，面对的指标可能成百上千，分别对其进行分析，工作量太大，可以在聚类的基础上再做建模分析。
- 指标关联分析：即分析指标A是否会对指标B有影响以及有什么样的影响
  - 正向/负向、先后关系、多少时间步后造成影响等等



# 数据处理

## 数据集

- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)

  包含约80个时间序列数据集

  - 意大利城市小时级空气质量
  - 糖尿病患者的活动饮食记录等

- [Time Series Classification Website](http://www.timeseriesclassification.com/index.php)

  - 更高质量的时间序列数据集
  

## 时间轴

当数据存储时并没有一列显式存在的**时间列**就需要人为构造

- 以**事件记录的时间**构造时间列
- 以**另一个和时间相关的元素**构造时间列
  - 例如在一个数据集中行驶距离和时间是正相关的，就可以用距离来构造时间列

- 以物理轨迹的顺序作为时间列
  - 例如在医学，天气等领域有些数据是以图片的形式存储的，此时可以从图像中提取时间列


## 时序处理

**时间戳**是一个十分重要的特征，但它可能存在一些问题

- 通常**事件发生的时间**和**事件被记录的时间**往往是不一致的

> 在处理历史遗留数据时并没有清洗记录的文档说明，也无法找到处理数据流的人来确认时间戳产生的方式。这时就需要调查和推断

## 清洗数据

**数据清洗方法**

- 缺失值处理
- 改变时间频率
- 平滑数据
- 处理季节性问题
- 防止无意识的向前看

### 缺失值处理

最常用的处理缺失值的方法包括填补和删除两种

- **填补**（Imputation）：基于完整数据集的其他值填补缺失值
  - 前向填充法（Forward fill）
  - 移动平均法（Moving average）
  - 插值法（Interpolation）
- **删除**（Deletion）：直接删除有缺失值的时间段



**前向填充法（Forward fill）**

填补数据最简单的方法之一，不需要任何数学或复杂逻辑

- 用缺失值之前出现的最近一个时间点的数值来填补缺失
- 计算简单，很容易用于**实时**流媒体数据

> 对应的有backward fill方法，要注意lookahead问题

**移动平均法（Moving average）**

某些场景下（例如数据的噪声很大，对于单个数据点有很大的波动）用移动平均的方法会比前向填充的方法效果更好（可以弱化这些噪声）

- 取出缺失值发生之前的**一段滚动时间内的值**，计算其平均值或中位数来填补缺失
- 计算均值时可以根据实际情况采取多种方法
  - 指数加权：给最近的数据点赋予更高的权重


**插值法（Interpolation）**

- 一种先验方法，希望整体数据表现的符合图像上的约束

> 在许多场景下，线性（或样条）插值都是非常合适的。但无规律的场景就不适合



### 修改时间频率

不同数据源的时间轴可能无法一一对应，此时需要用改变时间频率的方法进行数据清洗

**改变收集数据的频率**

- 上采样（UpSamping）
- 下采样（DownSampling）

> 无法改变实际测量数据的频率
>

#### 下采样

**减少数据收集的频率**，也就是从原始数据中抽取子集的方式

**应用场景**

- **数据原始的分辨率不合理**：例如有一个记录室外温度的数据，时间频率是每秒钟一次，实际上气温不会在秒钟这个级别有明显的变化，而且秒级的气温数据的测量误差甚至会比数据本身的波动还要大，因此这个**数据集有着大量的冗余**
- 关注**某个特定季节的信息**：例如某些数据存在季节性的波动，可以只选择某一个季节（或月份）进行分析
- **进行数据匹配**：例如有两个时间序列数据集，一个更低频（年度数据），一个更高频（月度数据），为了将两个数据集匹配进行下一步的分析，可以对高频数据进行合并操作，如计算年度均值或中位数，从而获得相同时间轴的数据集

#### 上采样

某种程度上是**凭空获得更高频率数据的方式**

- 使用上采样只是获得了更多的数据标签，而没有增加额外的信息

**应用场景**

- **不规律的时间序列**：用于处理多表关联中存在**不规则时间轴**的问题：例如现在有两个数据，一个记录了捐赠的时间和数量，另一个数据记录了公共活动的时间和代号，需要合并这两个表的数据，为每次捐赠打上标签，记录每次捐赠之前最近发生的一次公共活动

  > 这种操作叫做rolling join

- **进行数据匹配**：类似下采样的场景，例如有一个月度的失业率数据，为了和其他数据匹配需要转换成日度的数据，如果假定新工作一般都是从每个月第一天开始的，那么可以推演认为这个月每天的失业率都等于该月的失业率



### 平滑数据

数据平滑通常是为了**消除一些极端值或测量误差**

- 即使有些极端值本身是真实的，但是并**没有反应出潜在的数据模式**，也会把它平滑掉

**平滑技术**

- Weighted Averaging
- Exponential Smoothing（指数平滑法）
- Holt Exponential Smoothing
- Holt-Winters Exponential Smoothing 

**weighted averaging**

最简单的平滑技术，可以给予数据点相同的权重，也可以给越邻近的数据点更高的权重

> 就是moving average，需要为每一个权重指定一个确定值

**exponential smoothing**

本质上和weighted averaging类似，都是**给越邻近的数据点更高的权重**。区别在于衰减的方式不同，指数平滑法是**从最邻近到最早的数据点的权重呈现指数型下降的规律**

t时刻的**指数平滑后的值**可以用以下公式表示：

<center>S<sub>t</sub> = α * x<sub>t</sub> + (1-α) * S<sub>t-1</sub></center>

- S<sub>t</sub>，S<sub>t-1</sub>：表示当前时刻和**上一个时刻的平滑值**
- x<sub>t</sub>：表示**当前时刻的实际值**
- α：表示平滑系数，该系数越大则越近邻的数据影响越大

> 指数平滑法进一步加强了近期观察值对预测值的作用（加大了近期观察值的权数），使预测值能够迅速反映市场实际的变化
>
> 指数平滑法在很多场景下效果都很好，但它也有一个明显的缺点：无法应用于呈现趋势变化或季节性变化的数据

**Holt Exponential Smoothing**

通过引入一个额外的**趋势系数**解决了指数平滑无法应用于**具有趋势变化的数据**

> 依旧无法解决具有季节性变化数据的平滑问题

**Holt-Winters Exponential Smoothing**

通过再引入一个额外的**季节系数**来解决了Holt Exponential Smoothing无法应用于具有季节性变化的数据

> 在时间序列的预测上（例如未来销售数据预测）有着很广泛的应用



# 探索式数据分析

`Exploratory Data Analysis`：EDA

指对已有的数据（特别是调查或观察得来的原始数据）**在尽量少的先验假设下**进行探索，通过作图、制表、方程拟合、计算特征量等手段**探索数据的结构和规律**的一种**数据分析方法**

**通用方法**

- 直方图观察频率分布情况
- 散点图观察不同列的相关关系
- 折线图观察趋势变化

# 时序数据处理

对于时间序列数据

1. **平稳性**：是否反映一个平稳的系统
2. **自相关性**：是否存在一些**内部动态关系**

## 平稳性

通常来说一个平稳的时间序列指的是这个**时间序列在一段时间内具有稳定的统计值**（例如均值，方差），意味着过程的某些性质是不随时间而变化的

- **没有趋势**：序列在均值水平上不存在系统性变化
- **波幅恒定**：在方差上不存在系统性变化
- **没有严格地周期性变化**

### 弱平稳

- 均值、方差均为常数
  - $E(X_t^2)<∞$，$E(X_t^2) = C$

- **自协方差只和时间间隔有关**，与时间起点无关
  - 对任意k，$$γ_k = Cov(X_t,X_{t+k})$$与t无关


> 强平稳难以验证，一般只考虑弱平稳
>
> 时间序列中的协方差不需要两个变量，而是通过一定间隔的两个时间步的值计算

**平稳性的重要性**

时间序列建模**第一步是将时间序列转为平稳时间序列**

- 大量时间序列的统计学模型都是**基于平稳性的假设**
  - ARMA、AR、MA等模型只能用于预测平稳时间序列

- 对于一个应用于非平稳时间序列的模型，它的准确性和模型指标会随着时间序列本身变化而变化，从而造成模型本身不稳定
- 对于一个**非平稳的时间序列，可以通过一些简单的变换使之变成平稳性的**
  - **log变换**和**平方根变换**是两个常用的方式
    - 适用于非等方差的场景
  - 另外可以**通过差分变换的方式消除时间序列趋势**
    - 差分就是使用$x_t-x_{t-1}$代替$x_t$

> 在实践的过程中要谨防过于依赖直觉而被直觉所欺骗
>
> 对于很多时序预测模型尤其是深度学习模型，代码中可能并没有平稳性转换这一步。这是因为这些模型中往往有自动特征提取的步骤，从而隐性地完成平稳性转换

### ADF检验

`Augmented Dickey Fuller Test`：平稳性**假设检验**

- 迪基-福勒检验：`Dickey-Fuller Test`（DF检验）：可以测试一个自回归模型是否存在**单位根**（unit root），但是只有当序列为AR时才有效
  - **单位根**是一个使得时间序列**非平稳**的一个特征，如果序列平稳，就不存在单位根，否则，就会存在单位根

- ADF检验和DF检验类似，但ADF检验的优点在于它透过纳入落后期的一阶向下差分项，**排除了自相关的影响**
  - 落后期理论上可有无限多期，只要资料量容许


> 如果序列存在高阶滞后相关，就违背了扰动项是独立同分布的假设，所以提出了ADF来检验含有高阶序列相关的序列的单位根

```python
from statsmodels.tsa.stattools import adfuller
result = adfuller(data)
```



**公式**

在下面的公式中如果`α=1`，则存在单位根，即时间序列非平稳

<center>Y<sub>t</sub> = α * Y<sub>t-1</sub> + β * X<sub>e</sub> + λ

- Y<sub>t</sub>，Y<sub>t-1</sub>：分别表示t时刻和t-1时刻的时间序列值
- X<sub>e</sub>：表示外生变量
- λ：表示误差项

只有当`alpha<1`时，整个时间序列的趋势才是有可能出现逆转的。而ADF Test就是对alpha值的假设检验，它的原假设是`alpha =1`，即原假设成立则时间序列非平稳

**ADF Test的不足**

- 对于区分近似单位根（near unit roots）和单位根不是很有效
- 当数据点很少时，容易出现假阳性的问题
- 大多数测试不会检测所有导致非平稳的因素，例如有些测试只是检验均值或方差两者之一是否平稳，有些测试只是检验总体分布

> 因此在使用任何假设检验时都要先充分理解数据的特点和检验的限制因素



## 自相关性

自相关指时间序列中**某一个时刻的值和另一个时刻的值具有一定的相关性**

- 自相关函数（The autocorrelation function）
- 偏自相关函数（The partial autocorrelation function）

> 举例来说，有一个每天更新的气温数据，观察数据可能发现每年5月15号和8月15号的气温存在某种关联，当年5月15号更热，则对应的8月15号也更热。当然也可能这种关联性趋近于0， 知道5月15号的气温并不会得到任何关于8月15号气温的信息

### 自相关函数

ACF

一组时间序列和它前面间隔n个时刻的一组时间序列之间的**相关程度**

- 周期性序列的ACF值和原始序列具有相同的周期性
- 对几个周期性序列的和计算ACF值和分别计算每个周期性序列的ACF值再相加的结果相同
- 所有时间序列在间隔（lag）等于0时ACF值都为1
  - 时间序列和它本身之前具有完全的正相关性（ACF图的横轴就是间隔lag）

- 对于任何一个时间序列，它在5%的置信度下的acf值不显著为0的置信区间的临界值为$$\pm\frac{1.96}{\sqrt{T - d}}$$（T为样本量，d为时间间隔）
  - 从公式中可以得出，随着时间间隔d的增大，置信区间也是在不断增大的，也就是说**距离越远的相关性越不可信**

- 时间序列会包含趋势，季节性，周期性和残差等成分，ACF在寻找相关性时会考虑所有这些直接和间接的相关性信息

### 白噪声

white noise

**白噪声过程**：纯随机过程

**白噪声序列**：指白噪声过程的样本实称，简称**白噪声**

- 白噪声序列的特点表现在**任何两个时点的随机变量都不相关**，序列中没有任何可以利用的动态规律，即序列无**自相关性**，因此不能用历史数据对未来进行预测和推断
- 一个完全的白噪声序列，它在任何间隔处的ACF都近似于0

> 白噪声没有研究意义

### 偏自相关函数

PACF

一组时间序列和它前面间隔n个时刻的一组时间序列之间的**相关程度**

- 对于周期性时间序列pacf会迅速趋近于0，而不是像acf一样呈现周期性，所以pacf没有太多冗余信息存在（对于判断要收集多长的时间序列才能获取足够多的信息具有很大的帮助）
- pacf的置信区间临界值和acf相同

> 偏相关性可以从本质上理解为去除了样本之间的干涉，也就是更早时刻的相关性影响
>
> 计算时间间隔3的pacf是去除了时间间隔小于3的样本的影响而只计算由于时间间隔为3时的时间序列之间的相关性，因为时间间隔为1和2的样本的影响已经在前面的pacf函数中计算过了



## 虚假相关性

具有潜在趋势的数据很可能产生虚假的相关性，除了趋势之外，时间序列的其他一些共同特征也会引入虚假相关性

- 季节性，例如考虑夏天热狗消费量和溺水死亡人数的相关性
- 随着时间的推移，状态变化引起的数据水平或斜率变化
- 累计数量的相关性，这被许多行业广泛用于人为制造更强相关性的技巧

[虚假相关性案例](http://tylervigen.com/spurious-correlations)

> 并没有因果关系来解释这些高相关性，即这些都是所谓的虚假相关性。现实生活中有不可能有这么多真正的高相关性

## 可视化

- 一维数据可视化可以帮助理解个体的独立时间分布特点
- 二维数据可视化可以帮助理解某个变量值同时在时间轴和另一个变量维度上的轨迹特征
- 三维数据可视化虽然可以在更高的维度上观察数据，但是在可视化领域其实不太推荐使用这类图表，因为在视觉上不清晰，容易造成误导

> 时间序列数据中折线图是最适合的表现形式之一



# 统计学模型

## 自回归模型

Auto Regressive：AR

**前提**

- 时间序列数据是平稳的

- 数据之间非独立
  - 用历史预测未来

> 如果数据集是不平稳的，需要操作将数据去除趋势项和季节项使其变得平稳

**区别**

- **一般线性回归分析假定不同数据点之间是独立的**
- 时间序列数据分析的一个重要前提是各个数据点之间存在关联

> 一般自回归模型是在拟合时间序列数据时最先尝试的模型

### AR(1)

最简单的模型：用t-1时刻的时间序列值来拟合t时刻的时间序列值

$x_t = b_0+b_1*x_{t-1}+ e_t$

- (1)表示当前时刻的数据值的计算**只考虑到前一个时刻的值**
- b0，b1表示截距项和回归系数
- et表示噪声
  - t时刻的错误项，错误项均值为0


### AR(p)

$y_t = b_0+b_1*y_{t-1}+b_2*y_{t-2}+...+b_{t-p}*y_{t-p} e_t$

## 移动平均模型

Moving Average：MA

## 移动平均自回归模型

Auto Regressive Moving Average：ARMA

### 差分整合移动平均自回归模型

Autoregressive Integrated Moving Average：ARIMA

# 机器学习模型

xgboost

随机森林

SVM

# 深度学习模型

RNN

LSTM

